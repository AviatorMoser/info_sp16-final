{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "2bfe5ed8b49c3cce14972ef1c05ac66c",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "This notebook will be collected automatically at **6pm on Monday** from `/home/data_scientist/assignments/Week3` directory on the course JupyterHub server. If you work on this assignment on the course Jupyterhub server, just make sure that you save your work and instructors will pull your notebooks automatically after the deadline. If you work on this assignment locally, the only way to submit assignments is via Jupyterhub, and you have to place the notebook file in the correct directory with the correct file name before the deadline.\n",
    "\n",
    "1. Make sure everything runs as expected. First, restart the kernel (in the menubar, select `Kernel` → `Restart`) and then run all cells (in the menubar, select `Cell` → `Run All`).\n",
    "2. Make sure you fill in any place that says `YOUR CODE HERE`. Do not write your answer in anywhere else other than where it says `YOUR CODE HERE`. Anything you write anywhere else will be removed by the autograder.\n",
    "3. Do not change the file path or the file name of this notebook.\n",
    "4. Make sure that you save your work (in the menubar, select `File` → `Save and CheckPoint`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3.2. Supervised Learning: Support Vector Machine\n",
    "\n",
    "In this problem, we will use Support Vector Machine to see if we can use machine learning techniques to predict departure delays at the O'Hare airport (ORD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "c1b363e44a3d9ab4dc0291926b33c71a",
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.4/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n",
      "/opt/conda/lib/python3.4/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import svm, preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from nose.tools import assert_equal, assert_in, assert_is_not\n",
    "from numpy.testing import assert_array_equal, assert_array_almost_equal, assert_almost_equal\n",
    "from pandas.util.testing import assert_frame_equal, assert_index_equal\n",
    "\n",
    "sns.set(style=\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the 2001 on-time airline performance data set. We import the following columns:\n",
    "\n",
    "- Column 5: CRSDepTime, scheduled departure time (local, hhmm)\n",
    "- Column 8: UniqueCarrier, unique carrier code\n",
    "- Column 15: DepDelay, departure delay, in minutes\n",
    "- Column 16: Origin, origin IATA airport code\n",
    "- Column 18: Distance, in miles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "d61f9697709cf4e1dbbd13fcd7804b67",
     "grade": false,
     "grade_id": "read_csv",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    '/home/data_scientist/data/2001.csv',\n",
    "    encoding='latin-1',\n",
    "    usecols=(5, 8, 15, 16, 18)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, we use only `AA` flights (American Airlines, the largest airline using the O'Hare airport). Recall that we had an unbalanced data set by using `DepDelay > 15` in Problem 3.1. In this problem, we use `DepDelay > 0` to make our data set more balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "5551032b2841b1f97bd9bc220d694862",
     "grade": false,
     "grade_id": "local",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "local = df[(df['Origin'] == 'ORD') & (df['UniqueCarrier'] == 'AA')]\n",
    "local = local.drop(['UniqueCarrier', 'Origin'], axis=1) # we don't need the Month and Origin columns anymore.\n",
    "local['Delayed'] = (local['DepDelay'] > 0).astype(np.int) # 1 if a flight was delayed, 0 if not.\n",
    "local = local.drop('DepDelay', axis=1).dropna() # we don't need the DepDelay column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the number of delayed flights to non-delayed flights and check if we have a balanced data set.\n",
    "\n",
    "```python\n",
    ">>> print('Delayed: {}\\nNot delayed: {}'.format(\n",
    "    (local.Delayed == 0).sum(),\n",
    "    (local.Delayed == 1).sum()\n",
    "    ))\n",
    "```\n",
    "\n",
    "```\n",
    "Delayed: 61932\n",
    "Not delayed: 44006\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "76f35d1487c081a1dc58253a26663921",
     "grade": false,
     "grade_id": "print_local_delayed",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delayed: 61932\n",
      "Not delayed: 44006\n"
     ]
    }
   ],
   "source": [
    "print('Delayed: {}\\nNot delayed: {}'.format(\n",
    "    (local.Delayed == 0).sum(),\n",
    "    (local.Delayed == 1).sum()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the first few columns and see what we'll be working with.\n",
    "\n",
    "```python\n",
    ">>> print(local.head(5))\n",
    "```\n",
    "\n",
    "```\n",
    "        CRSDepTime  Distance  Delayed\n",
    "398444        1905      1846        1\n",
    "398445        1905      1846        1\n",
    "398446        1905      1846        1\n",
    "398447        1905      1846        0\n",
    "398448        1905      1846        1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "a21dce3e8525d5c0130ef5fcc3f26831",
     "grade": false,
     "grade_id": "print_local_head",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        CRSDepTime  Distance  Delayed\n",
      "398444        1905      1846        1\n",
      "398445        1905      1846        1\n",
      "398446        1905      1846        1\n",
      "398447        1905      1846        0\n",
      "398448        1905      1846        1\n"
     ]
    }
   ],
   "source": [
    "print(local.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split\n",
    "\n",
    "Write a function named `split()` that takes a DataFrame as its first argument. The second argument `test_column` specifies which column should be used as a label (`Delayed` in our case). All remaining columns except `test_column` should be used for training. In other words, the returned DataFrames `y_train` and `y_test` both have only one column, `test_column`, and `X_train` and `X_test` contain all columns in `df` minus `test_column`.\n",
    "\n",
    "This function is (almost) the same function we wrote in Problem 3.1. You could simply cut and paste the answer. But cut-and-pasting is boring (and it's easier to work with Numpy arrays in this problem), so let's modify the function a little bit and **return Numpy arrays** this time. Pay close attention to the shape of `y_train` and `y_test` arrays: they should be **row vectors**, not column vectors.\n",
    "\n",
    "```python\n",
    ">>> print(local[['Delayed']].values[:5]) # column vector\n",
    "```\n",
    "\n",
    "```\n",
    "[[0]\n",
    " [0]\n",
    " [0]\n",
    " [1]\n",
    " [0]]\n",
    "```\n",
    "\n",
    "```python\n",
    ">>> print(local[['Delayed']].values.shape) # column vector\n",
    "```\n",
    "\n",
    "```\n",
    "(341284, 1)\n",
    "```\n",
    "\n",
    "```python\n",
    ">>> print(local_delayed_as_a_row_vector[:5])\n",
    "```\n",
    "\n",
    "```\n",
    "[0 0 0 1 0]\n",
    "```\n",
    "\n",
    "```python\n",
    ">>> print(local_deayed_as_a_row_vector.shape)\n",
    "(341284,)\n",
    "```\n",
    "\n",
    "Don't forget that we have to pass an instance of `check_random_state()` to the `train_test_split()` function for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "a569848107aadee3589421e2c7224663",
     "grade": false,
     "grade_id": "split_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def split(df, test_column, test_size, random_state):\n",
    "    '''\n",
    "    Uses sklearn.train_test_split to split \"df\" into a testing set and a test set.\n",
    "    The \"test_columns\" lists the column that we are trying to predict.\n",
    "    All columns in \"df\" except \"test_columns\" will be used for training.\n",
    "    The \"test_size\" should be between 0.0 and 1.0 and represents the proportion of the\n",
    "    dataset to include in the test split.\n",
    "    The \"random_state\" parameter is used in sklearn.train_test_split.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: A pandas.DataFrame\n",
    "    test_columns: A list of strings\n",
    "    test_size: A float\n",
    "    random_state: A numpy.random.RandomState instance\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A 4-tuple of numpy.ndarrays\n",
    "    '''\n",
    "    ##################\n",
    "    X = df.drop(test_column, axis=1).values\n",
    "    y = df[test_column].values.transpose()[0]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state = random_state)\n",
    "    ##################\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will split `local` into a training set and a test set. We won't use a validation set this time, because training SVM is more computationally expensive than training a $k$-Nearest Neighbors. However, keep in mind that SVM also has hyperparameters that need to be tuned, e.g., `kernel`, `C`, or `gamma` values. In practice, you should create a validation set, or preferably perform a cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "e9e1349c4e44f01d444073b7fd151c91",
     "grade": false,
     "grade_id": "split_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split(\n",
    "    df=local,\n",
    "    test_column=['Delayed'],\n",
    "    test_size=0.4,\n",
    "    random_state=check_random_state(0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "d6bb7f6aeb67e52f42bd5788f88bdfe3",
     "grade": true,
     "grade_id": "split_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "n_samples_train, n_features_train = X_train.shape\n",
    "n_samples_test, n_features_test = X_test.shape\n",
    "\n",
    "assert_equal(n_features_train, 2)\n",
    "assert_equal(n_features_test, 2)\n",
    "n_features = n_features_train\n",
    "\n",
    "assert_equal(np.abs(n_samples_train - np.round(len(local) * 0.6)) <= 1, True)\n",
    "assert_equal(np.abs(n_samples_test - np.round(len(local) * 0.4)) <= 1, True)\n",
    "\n",
    "assert_array_equal(X_train[:5],\n",
    "    np.array(\n",
    "        [[ 1500.,  1846.],\n",
    "         [ 1415.,   802.],\n",
    "         [ 1138.,   409.],\n",
    "         [ 1649.,   723.],\n",
    "         [ 1835.,   678.]]\n",
    "        ))\n",
    "assert_array_equal(X_test[:5],\n",
    "    np.array(\n",
    "        [[  645.,  1745.],\n",
    "         [  620.,   622.],\n",
    "         [  645.,  1745.],\n",
    "         [ 2040.,   678.],\n",
    "         [  835.,   268.]]\n",
    "        ))\n",
    "\n",
    "assert_array_equal(y_train[:10], np.array([1, 0, 1, 0, 1, 1, 1, 1, 0, 1]))\n",
    "assert_array_equal(y_test[:10], np.array([1, 1, 0, 0, 0, 0, 0, 1, 1, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale\n",
    "\n",
    "In Problem 3.1, we saw that the columns we want to use for training have different scales, so we scaled each column to the [0, 1] range. For SVM, we will scale features to be in [-1, -1] range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "c5d41cd6bd13121b8840dbced72a5927",
     "grade": false,
     "grade_id": "standardize_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def standardize(x):\n",
    "    '''\n",
    "    Takes a 2d array and normlizes each feature (each column) to be in range [-1, 1].\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    array: A numpy.ndarray\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A numpy.ndarray\n",
    "    '''\n",
    "    ##################\n",
    "    x_min = x.min(axis=0)[np.newaxis,:]\n",
    "    x_max = x.max(axis=0)[np.newaxis,:]\n",
    "    \n",
    "    scaled = (x - x_min)/(x_max-x_min)*2-1\n",
    "    ##################\n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "c9cef05e72b84ee75f2cd16c54a1c1bb",
     "grade": true,
     "grade_id": "standardize_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "array_t = np.array(\n",
    "    [[-4,  3,  0, -5, -3],\n",
    "     [-2, -3,  1,  3, -1],\n",
    "     [-3,  1,  3,  1,  0]]\n",
    "    )\n",
    "\n",
    "scaled_t = standardize(array_t)\n",
    "assert_array_almost_equal(scaled_t, np.array(\n",
    "    [[-1., 1. , -1., -1., -1.],\n",
    "     [ 1., -1., -0.33333333, 1., 0.33333333],\n",
    "     [ 0., 0.33333333, 1., 0.5, 1.]]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "c1f6d46e1aca7091ea9afe0f42c6a1c6",
     "grade": false,
     "grade_id": "standardize_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X_train_scaled, X_test_scaled = map(standardize, [X_train, X_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SVM\n",
    "\n",
    "Now that we have standardized the training set, we are ready to apply the SVM algorithm.\n",
    "\n",
    "Write a function named `fit_and_predict()`. It should return a tuple of `(svm.SVC, np.ndarray)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "08d138ef94ae384c774ac9ae94deb0e9",
     "grade": false,
     "grade_id": "fit_and_predict_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def fit_and_predict(X_train, y_train, X_test, kernel):\n",
    "    '''\n",
    "    Fits a Support Vector Machine on the training data on \"X_train\" and \"y_train\".\n",
    "    Returns the predicted values on \"X_test\".\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: A numpy.ndarray\n",
    "    y_train: A numpy.ndarray\n",
    "    X_test: A numpy.ndarray\n",
    "    kernel: A string that specifies kernel to be used in SVM\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    model: An svm.SVC instance trained on \"X_train\" and \"y_train\"\n",
    "    y_pred: A numpy array. Values predicted by \"model\" on \"X_test\"\n",
    "    '''\n",
    "    ##################\n",
    "    model = svm.SVC(kernel=kernel)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    ##################\n",
    "\n",
    "    return model, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training SVM on `X_train` and `y_train` will take a while, so let's first make sure that the function works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "6d6ca0a3aa1c1d6f604c132e8ace563b",
     "grade": true,
     "grade_id": "fit_and_predict_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# toy sample\n",
    "X_train_t = [[-2, -1], [-1, -1], [-1, -2], [1, 1], [1, 2], [2, 1]]\n",
    "y_train_t = [1, 1, 1, 2, 2, 2]\n",
    "X_test_t = [[-1, -1], [2, 2], [3, 2]]\n",
    "y_test_t = [1, 2, 2]\n",
    "\n",
    "model1, pred1 = fit_and_predict(X_train_t, y_train_t, X_test_t, 'linear')\n",
    "assert_equal(isinstance(model1, svm.SVC), True)\n",
    "assert_equal(model1.kernel, 'linear')\n",
    "assert_array_equal(pred1, y_test_t)\n",
    "\n",
    "model2, pred2 = fit_and_predict(X_train_t, y_train_t, X_test_t, 'rbf')\n",
    "assert_equal(model2.kernel, 'rbf')\n",
    "assert_array_equal(pred2, y_test_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to actually train on the flights data. It might take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "4a05a776b33e9faa1b218fab0f5d7d0d",
     "grade": false,
     "grade_id": "fit_and_predict_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "clf, y_pred = fit_and_predict(X_train_scaled, y_train, X_test_scaled, 'rbf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the accuracy score is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "e55cea295dea8d5fac7e64c9e18bd528",
     "grade": false,
     "grade_id": "fit_and_predict_print",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.593779497829\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like using only two features `CRSDepTime` and `Distance` really hurt our performance (and predicting flight delays is a hard problem). To improve performance, we probably need to include more features, and not just the features provided in `2001.csv`, but data from other sources. For example, I would guess that weather has a significant impact on flights delays. One possibility is to find historical weather data (which will likely require using techniques you learned in the previous course) and include weather as a feature.\n",
    "\n",
    "## Confusion matrix\n",
    "\n",
    "Plot a a colored heatmap that displays the relationship between predicted and actual types. The `plot_confusion()` function must return a `maplotlib.axes.Axes` object. Use `numpy.histogram2d()` and `seaborn.heatmap()` as demonstrated in lesson 1. Here's an exmaple:\n",
    "\n",
    "![](https://raw.githubusercontent.com/UI-DataScience/info490-sp16/master/Week3/assignments/images/svm_confusion.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "abe06fd5102503137377f35d3f7fc7c1",
     "grade": false,
     "grade_id": "plot_confusion_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_confusion():\n",
    "    '''\n",
    "    Plots a confusion matrix using numpy.histogram2d() and seaborn.heatmap().\n",
    "    Returns a maptlotlib.axes.Axes instance.\n",
    "    '''\n",
    "    ##################\n",
    "    x = y_test\n",
    "    y = y_pred\n",
    "    \n",
    "    hist = np.histogram2d(x, y, bins=2)[0]\n",
    "    ax = sns.heatmap(hist, annot=True, fmt = '.0f')\n",
    "    \n",
    "    ax.set_xticklabels(['Not delayed', 'Delayed'])\n",
    "    ax.set_yticklabels(['Delayed', 'Not delayed'])\n",
    "    ax.title.set_text('Confusion Matrix for SVM')\n",
    "    ##################\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "9f3d95c61088364e89b9095d190ed68b",
     "grade": false,
     "grade_id": "plot_confusion_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdEAAAFhCAYAAAAvCZDuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f150c7bb198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plot_confusion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "d1e56d610570ac84309ea6af9c4c8e84",
     "grade": true,
     "grade_id": "plot_confusion_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(isinstance(ax, mpl.axes.Axes), True, msg=\"Your function should return a matplotlib.axes.Axes object.\")\n",
    "\n",
    "texts = [t.get_text() for t in ax.texts]\n",
    "assert_equal(texts, ['14971', '2712', '22450', '2243'])\n",
    "             \n",
    "x_tick_labels = [l.get_text() for l in ax.get_xticklabels()]\n",
    "y_tick_labels = [l.get_text() for l in ax.get_yticklabels()]\n",
    "assert_equal(y_tick_labels, ['Delayed', 'Not delayed'])\n",
    "\n",
    "assert_is_not(len(ax.title.get_text()), 0, msg=\"Your plot doesn't have a title.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
