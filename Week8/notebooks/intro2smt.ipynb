{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<DIV ALIGN=CENTER>\n",
    "\n",
    "# Introduction to Social Media: Twitter\n",
    "## Professor Robert J. Brunner\n",
    "  \n",
    "</DIV>  \n",
    "-----\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Introduction\n",
    "\n",
    "\n",
    "When looking for data to use for text data processing, one of the more\n",
    "popular data sources is [Twitter][tw]. In this Notebook, we introduce\n",
    "the Twitter API, and demonstrate how to use the Twitter API from within\n",
    "a Python gram to acquire and process tweets, or Twitter messages. First,\n",
    "we review the mechanisms by which an application authenticates with\n",
    "Twitter. Next, we discuss different techniques for interacting with the\n",
    "twitter data stream by using the twitter API. Finally, we construct a\n",
    "tweet sentiment analysis pipeline before applying this pipeline to new\n",
    "tweets from a specific user.\n",
    "\n",
    "-----\n",
    "[tw]: https://www.twitter.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python and Twitter\n",
    "\n",
    "To work with the Twitter API from within a Python program, we need a\n",
    "Python library that wraps the official [Twitter API][twapi]. There are a\n",
    "number of different Python libraries that provide this capability, we\n",
    "will use the [tweepy][tpy] library, which is fairly popular and provides\n",
    "a fairly complete interface.\n",
    "\n",
    "The full Twitter API is large and robust (and continuous to evolve),\n",
    "for this course we will restrict our attention to several basic\n",
    "concepts, namely authenticating to Twitter, searching for Tweets, and\n",
    "digesting the messages.\n",
    "\n",
    "----\n",
    "[twapi]: https://dev.twitter.com\n",
    "[tpy]: http://www.tweepy.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tweepy as tw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "-----\n",
    "\n",
    "## Reading Twitter Data\n",
    "\n",
    "To read twitter data, you need to first need to be a registered Twitter\n",
    "user and you need to create a new _Twitter Application_ in order to\n",
    "obtain credentials for connecting to Twitter and querying to the\n",
    "Twitter data. You create (and later manage) Twitter applications by\n",
    "visting the [Twitter Application Management](https://apps.twitter.com)\n",
    "website.\n",
    "\n",
    "![Twitter App Sign-in](images/twitter-app-signin.png)\n",
    "\n",
    "At this point you need to authenticate with Twitter, if you are already\n",
    "logged in to Twitter on your computer (for instance by using the Twitter\n",
    "website) you should already be authenticated. If you are not\n",
    "authenticated, click the _sign in_ link to be directed to the Twitter\n",
    "signin page where you can enter your credentials (if you do not have\n",
    "Twitter credentials, you will need to obtain a Twitter account to\n",
    "proceed).\n",
    "\n",
    "![Twitter Sign-in](images/twitter-signin.png)\n",
    "\n",
    "After you have been authenticated, you will be redirected to the Twitter\n",
    "apps page. If you have never created a Twitter application, you will\n",
    "have nothing listed. To create a new application, press the _Create New\n",
    "App_ button, as shown in the following screenshot.\n",
    "\n",
    "![Twitter Create App](images/twitter-create.png)\n",
    "\n",
    "This will open up the Twitter _Create an application_ webpage, where you\n",
    "need to supply some basic information for your Twitter application such\n",
    "as an application name, description, and website.\n",
    "\n",
    "![Twitter Application details](images/twitter-appdetails.png)\n",
    "\n",
    "Scroll to the bottom of this webpage where the **Developer Agreement**\n",
    "is located. Following this agreement, is a check box that you should\n",
    "click to signify you agree to be bound by the agreement (of course you\n",
    "should read this to be sure you do _agree_ with it first). Following\n",
    "this, press the _Create your Twitter application_ button as shown in the\n",
    "following screenshot.\n",
    "\n",
    "![Twitter Agree](images/twitter-agree.png)\n",
    "\n",
    "This will create your new application, and provide you with your\n",
    "application webpage, which will be similar to the following screenshot.\n",
    "\n",
    "![Twitter Apppage](images/twitter-apppage.png)\n",
    "\n",
    "While you can control a number of application features from this\n",
    "webpage, the most important tasks to complete include:\n",
    "\n",
    "1. Change your application to _read-only_ in case it is set to\n",
    "read-write.\n",
    "\n",
    "2. Obtain the application **Consumer Key** and **Consumer Secret**.\n",
    "\n",
    "3. Obtain your personal **Access Token** and **Access Token Secret**.\n",
    "\n",
    "You should change your application read-only to ensure you don't\n",
    "accidentally send data out to Twitter. You change this by selecting the\n",
    "_Permissions_ tab and selecting _Read only_, shown in the following\n",
    "screenshot. To save this setting, scroll down this webpage and click the\n",
    "_Update Settings_ button at the bottom of the page.\n",
    "\n",
    "![Twitter Read Only Setting](images/twitter-ro.png)\n",
    "\n",
    "These credentials can be found by selecting the _Keys and Access Tokens_\n",
    "tab, and scrolling down appropriately as shown in the following two\n",
    "screenshots.\n",
    "\n",
    "![Twitter Consumer Application Credentials](images/twitter-consume.png)\n",
    "\n",
    "![Twitter User Credentials](images/twitter-access.png)\n",
    "\n",
    "<font color='red'>Warning: Never share these credentials with others or\n",
    "they will be able to fully impersonate you on Twitter!</font>\n",
    "\n",
    "You can directly copy these credentials into your Notebook, or,\n",
    "alternatively, save them into a file (for example by opening a terminal\n",
    "window and using `vim` to create a text file. In the rest of this\n",
    "Notebook, I demonstrate this functionality by using my credentials,\n",
    "which I have saved into a file called`twitter.cred'. In this empty file,\n",
    "which is in your github repository, I have saved the following four\n",
    "credentials in order:\n",
    "\n",
    "1. Access Token\n",
    "2. Access Token Secret\n",
    "3. Consumer Key\n",
    "4. Consumer Secret\n",
    "\n",
    "You can inform `git` to ignore changes in the `twitter.cred` file by\n",
    "using the folloqing command:\n",
    "\n",
    "```bash\n",
    "git update-index --assume-unchanged Week8/notebooks/twitter.cred \n",
    "```\n",
    "\n",
    "The following code cell demonstrates how these credentials are read from\n",
    "the file and used to properly authenticate our application with Twitter.\n",
    "\n",
    "-----\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter Screen Name:  AviatorMoser\n",
      "Twitter Follower Count:  5\n"
     ]
    }
   ],
   "source": [
    "tokens = []\n",
    "\n",
    "# Order: Access Token, Access Token Secret, Consumer Key, Consumer SecretAccess\n",
    "\n",
    "with open(\"twitter.cred\", 'r') as fin:\n",
    "    for line in fin:\n",
    "        if line[0] != '#': # Not a comment line\n",
    "            tokens.append(line.rstrip('\\n'))\n",
    "\n",
    "auth = tw.OAuthHandler(tokens[2], tokens[3])\n",
    "auth.set_access_token(tokens[0], tokens[1])\n",
    "\n",
    "api = tw.API(auth)\n",
    "\n",
    "user = api.me()\n",
    "\n",
    "print(\"Twitter Screen Name: \", user.screen_name)\n",
    "print(\"Twitter Follower Count: \", user.followers_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "If the previous code cell runs without an error, you have successfully\n",
    "connected to twitter. If you are new to twitter and are not following\n",
    "anyone, you can instead display the user information for a different\n",
    "Twitter user. For example, the following code would display my Twitter\n",
    "information.\n",
    "\n",
    "```python\n",
    "user = api.get_user('ProfBrunner')\n",
    "```\n",
    "\n",
    "Replacing `ProfBrunner` with any valid Twitter user id will display\n",
    "their information. You can find examples by looking at those Twitter\n",
    "users you (or `ProfBrunner`) follow. Or, alternatively, you could chose\n",
    "a specific twitter account; for example, to analyze the _NY Times_\n",
    "twitter account you would use the following statement:\n",
    "\n",
    "```python\n",
    "user = api.get_user('NYTimes')\n",
    "```\n",
    "\n",
    "This is demonstrated in the following code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter Screen Name:  nytimes\n",
      "Twitter Follower Count:  25286094\n",
      "\n",
      "This user follows:\n",
      "--------------\n",
      "emrosenberg\n",
      "azamsahmed\n",
      "BenWeiserNYT\n",
      "Wesley_Morris\n",
      "Yamiche\n",
      "ChanellePrice\n",
      "TwitterMoments\n",
      "poniewozik\n",
      "thunderwooddd\n",
      "migold\n",
      "timrace\n",
      "NYT_IR\n",
      "SciFleur\n",
      "geminiimatt\n",
      "mbeditor\n",
      "gregfwinter\n",
      "meredith_levien\n",
      "mmcintire\n",
      "mccarthyryanj\n",
      "MikaylaBouchard\n"
     ]
    }
   ],
   "source": [
    "user = api.get_user('nytimes')\n",
    "\n",
    "print(\"Twitter Screen Name: \", user.screen_name)\n",
    "print(\"Twitter Follower Count: \", user.followers_count)\n",
    "\n",
    "print(\"\\nThis user follows:\\n--------------\")\n",
    "for friend in user.friends():\n",
    "    print(friend.screen_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At any point, you can return to your Twitter application management\n",
    "webpage to view your new application. You can now view and manage your\n",
    "existing application, or create a new application as shown in the\n",
    "following screenshot.\n",
    "\n",
    "![Twitter new app management](images/twitter-manage.png)\n",
    "\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### Student Activity\n",
    "\n",
    "To run the Twitter application in the preceding cells, you will need to register your own Twitter Application. To do so, complete the following steps.\n",
    "\n",
    "1. Create a New Twitter application.\n",
    "\n",
    "2. Save your Twitter credentials and Application credentials into the\n",
    "provided `twitter.cred` file.\n",
    "\n",
    "3. Run the _tweepy_ sample code to connect to Twitter and display your\n",
    "Twitter user information.\n",
    "\n",
    "Finally, try running the preceding code, but for someone famous (if you do not know the twitter handle for someone famous, google will be your friend). \n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Tweets\n",
    "\n",
    "Once you have authenticated with Twitter, you can begin to [search the\n",
    "Twitter stream][stw] for tweets of interest. The easiest method to get started\n",
    "is to being with your own (or another specific Twitter user's) own\n",
    "Twitter feed. To access your own Twitter feed, you can simply use your\n",
    "`home_timeline` to retrieve your own Tweets or Tweets from those whom\n",
    "you follow. This is demonstrated in the following code cell, where we\n",
    "display the `text` values from the ten most recent Tweets from our\n",
    "timeline.\n",
    "\n",
    "-----\n",
    "[stw]: https://dev.twitter.com/rest/public/search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @Space_Station: Why do science in space? The @Space_Station is the one lab where we can use gravity as a variable.  https://t.co/E92fJO2…\n",
      "RT @humblebooks: Venture into the world of fully dramatized versions of The Lord of the Rings with our new audiobook bundle! https://t.co/G…\n",
      "LIVE NOW: Get to know the crew traveling to @Space_Station this summer. Qs? Use #askNASA: https://t.co/rUrtFCMVVq https://t.co/SNvceuoaHk\n",
      "TODAY: Meet the crew launching to @Space_Station this summer at 2pm ET. Watch &amp; #askNASA: https://t.co/SZBvaJyLAI https://t.co/eArHffcDAn\n",
      "RT @ISS_Research: Meet astronaut Kate Rubins and her crewmates during today's news conference. 2 p.m. EST https://t.co/sXUIX8NkCF https://t…\n",
      ".@SOFIAtelescope data indicates star eruptions create elements that can form rocky planets: https://t.co/m3xUh6xVln https://t.co/KBY5fqAK8H\n",
      "RT @humblebooks: Only 4 hours left! Last chance to get the Humble RPG Book Bundle: Pathfinder from @paizo https://t.co/5cpAP5Qzi7\n",
      "RT @unicefusa: Wow, @humble bundle added more #StarWars games to #ForceForChange bundle, which helps support UNICEF! Check it out: https://…\n",
      "RT @astro_timpeake: I never imagined a desert could look so magnificent https://t.co/8EvfVkm5V5\n",
      "ARTICLE: Mars set to receive NASA InSight at the end of 2018 - https://t.co/sUo0Z1uiQy https://t.co/8mlYYV6DJu\n",
      "Save the Date: @NASAInSight lander team now working toward a May 5, 2018 launch to Mars: https://t.co/epnuSp4arG https://t.co/GSjYlF12DB\n",
      "NASA’s (InSight) mission to Mars now targeting a new launch window that opens May 5, 2018. On Mars Nov. 26, 2018. https://t.co/5fohepr01X\n",
      "Five years! In some ways it doesn't seem that long ago, but in another way it seems like a completely different era! https://t.co/pg5BAmw5yP\n",
      "Mission Success! Ariane 5 successfully launches with Eutelsat 65 West A - https://t.co/azXUbffouy https://t.co/z2y5whn4p6\n",
      "LAUNCH! Ariane 5 launches with Eutelsat 65 West A - Follow along: https://t.co/JDiXC4ltNw https://t.co/23zQAEnAM8\n",
      "LIVE Coverage: Ariane 5 Flight VA229 with Eutelsat 65 West A - UPDATES: https://t.co/h6Pa3MV91x https://t.co/QQslxYyWaz\n",
      "RT @astro_tim: #GoodNight @Space_Station https://t.co/A7dMQxq9Ba\n",
      "Wow, a total solar #eclipse2016! See the moon pass directly in front of the sun. It happened at 8:38 to 8:42 pm ET. https://t.co/qK6O4xppbn\n",
      "Watch Now: Live stream of total solar #Eclipse2016! Event occurs over SE Asia at 8:38pm ET: https://t.co/QNdz0b0DQJ  https://t.co/lvsFO0SFkT\n",
      "LIVE NOW: Total solar #Eclipse2016 coverage! Event occurs over SE Asia at 8:38pm ET. Watch: https://t.co/QNdz0b0DQJ https://t.co/suaGqfuDln\n",
      "Live coverage of tonight's total solar #Eclipse2016 over SE Asia starts at 8pm ET. Watch: https://t.co/yTXkujNaxY https://t.co/oXNrPQYHeI\n",
      "People in parts of SE Asia will see a total solar #Eclipse2016 tonight. See why this happens https://t.co/SpXqLCSFyE https://t.co/4Au0qPRNcf\n",
      "RT @julzranaldi: idk I just need something new\n",
      "Tonight, catch a brighter Jupiter in the sky during its close encounter with Earth. Details: https://t.co/kZxtRfmmVy\n",
      "https://t.co/HepshZLwld\n",
      "RT @_OliviaSavino_: I'm wearing flip flops tomorrow idc\n",
      "damn yo i feel like i could sleep for a fortnight\n",
      "RT @google: .@NASA Ready for liftoff! 🚀 #OneDayIWill https://t.co/vaDy08oZl0\n",
      "Three more games added to our Star Wars Bundle! Pay what you want and support @UNICEF Kid Power! #ForceForChange https://t.co/7YmXzIw6o4\n",
      "Total solar #Eclipse2016 at 8:38pm ET. Not in SE Asia to see it? Watch online at 8pm: https://t.co/3ZAalcm7US.nasatv\n",
      "https://t.co/NNwlxtTww7\n",
      "@NASASpaceflight Port Canaveral says it's \"baffled\" by the surge in job applications for \"deck sweeping\" over the last hour. #OneWasMe\n",
      "Me and my boy are at iHop someone pull up\n",
      "I think she's dead, Jim. https://t.co/FGmQO30744 and https://t.co/l6qSN05YY2 https://t.co/UpyBouB3MD\n",
      "#OneDayIWill #JourneyToMars. Meet four women who can't wait to go: https://t.co/NvlyzmyUfr #InternationalWomensDay https://t.co/BWgNs25Sbs\n",
      "Humble Jumbo Bundle 6 is here with Dreamfall Chapters, Magicka 2, Grey Goo Definitive Edition, and more! https://t.co/TnjcgLUtps\n",
      "Lots coming up! Ariane 5 launch at an ungodly hour tonight. EM-2 Profile news. SLS RS-25 static fire. PSLV launch. Soyuz/Resurs launch.\n",
      "LIVE NOW: @Reddit AMA on today’s solar #Eclipse2016. Ask us anything about eclipse science: https://t.co/DhCjEHDWFZ https://t.co/KbrvqEv0AZ\n",
      "LMAOOO SHE HAD FAKE YEEZYS ONNNN\n",
      "@NASASpaceflight To add, the full hi res are on the link and downloadable for those wanting fine detail. I Greenshot images for Twitter. ;-)\n",
      "SpaceX ASDS photos from NSF member. Looks like some of the deceased F9 is still on deck. https://t.co/JbE1SeI0hi https://t.co/d33wkFUY8T\n",
      "Only 4 hours left! Last chance to get Humble Indie Bundle 16! https://t.co/ew3c7IRpgf\n",
      "Saturn's moons Tethys and Rhea (left and right, respectively) spotted by @CassiniSaturn: https://t.co/gaSpb8inYW https://t.co/Vqpu8Ebvz9\n",
      "Who wants to go to IHOP for free pancakes? I have early dismissal but I can go whenever\n",
      "One day we'll see a Falcon 9 first stage on the ASDS deck (intact and ready for another mission) https://t.co/zdaKmcqe6T\n",
      "@NASASpaceflight Morning jog for a Florida lady. Morning tug for the ASDS. https://t.co/pVMDaaDT4s\n",
      "@NASASpaceflight She may look a bit angry too, as word is she got wacked pretty hard by the returning Falcon 9 S1.\n",
      "SpaceX's ASDS \"Of course I still love you\" due back in port shortly. Following here: https://t.co/3nJ2qVlnCR\n",
      "Total solar eclipse! Not in SE Asia tomorrow to see it? No worries. Watch live at 8pm ET: https://t.co/qrm0Dz4jPE\n",
      "https://t.co/1h7UUmaUrl\n",
      "Space race competition helps entrepreneurs turn @NASA_Technology into new products: https://t.co/gfdkNvXjdc https://t.co/71YbdFqu0D\n",
      "Citizen scientists can help us understand auroras, features of geomagnetic storms. See how: https://t.co/wsTYsIwJqU https://t.co/bqc7iYtZ8P\n",
      "RT @Space_Station: Missing @StationCDRKelly's pics from space? Follow @astro_timpeake &amp; @astro_tim, currently on the @Space_Station. https:…\n"
     ]
    }
   ],
   "source": [
    "for tweet in tw.Cursor(api.home_timeline).items(50):\n",
    "    # Process a single status\n",
    "    print(tweet.text) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Searching\n",
    "\n",
    "Twitter also provides the capability to search for specific tweets by\n",
    "using the Tweepy [`search` method][twse]. In this method, you supply a\n",
    "query string (and optional arguments) and are returned a list of Tweets.\n",
    "The query string should follow the [Twitter Search API][tsa], but\n",
    "basically you can search for specific text in a string by using the text\n",
    "of interest, you can search for a person by using the `@` character\n",
    "followed by their Twitter username, and hashtags by using the `#`\n",
    "character followed by the tag text.\n",
    "\n",
    "-----\n",
    "\n",
    "[twse]: http://docs.tweepy.org/en/stable/api.html#API.search\n",
    "[tsa]: https://dev.twitter.com/rest/public/search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet ID: 707664854597935105\n",
      "Tweeted by  Baturyna_Elena\n",
      "Created at  2016-03-09 20:30:23\n",
      "Location:  Twitter for iPhone\n",
      "Tweet Text:  RT @pchikov: @gorod095 @gruppa_voina @U2_Keen извини нас с чуваками в масках\n",
      "-------------------------\n",
      "Tweet ID: 707664836499529729\n",
      "Tweeted by  PlayingOnKFMC\n",
      "Created at  2016-03-09 20:30:19\n",
      "Location:  Securenet Systems Radio Playlist Update\n",
      "Tweet Text:  U2 - Desire https://t.co/JEX5g1bSDG #realclassicrock #nowplaying\n",
      "-------------------------\n",
      "Tweet ID: 707664830719791104\n",
      "Tweeted by  Baturyna_Elena\n",
      "Created at  2016-03-09 20:30:18\n",
      "Location:  Twitter for iPhone\n",
      "Tweet Text:  RT @gorod095: @pchikov @gruppa_voina @U2_Keen да ты ж ебанись, мы уже не успеем заметку в третий раз переписать (\n",
      "-------------------------\n",
      "Tweet ID: 707664795617632256\n",
      "Tweeted by  RK_U2\n",
      "Created at  2016-03-09 20:30:09\n",
      "Location:  Twitter for iPhone\n",
      "Tweet Text:  RT @SkyNews: This is the ex-IS militant who provided Sky News with the details of thousands of jihadis and their families https://t.co/M6l7…\n",
      "-------------------------\n",
      "Tweet ID: 707664791293272064\n",
      "Tweeted by  GabrielElmurz\n",
      "Created at  2016-03-09 20:30:08\n",
      "Location:  Twitter for Android\n",
      "Tweet Text:  @U2_Keen @KevorkovaNadia извините их. Это менты так на Кавказе стучатся.  Если Ваня , то на втэрах стучатся\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "# Hash Tage search: term = '#python'\n",
    "# User search: term = '@nytimes'\n",
    "# Keyword search: term = 'data science'\n",
    "# Keyword and Sentiment: term ='data science :)' # Positive attitute\n",
    "\n",
    "term = 'U2'\n",
    "num_tweets = 5\n",
    "\n",
    "for tweet in tw.Cursor(api.search, q=term).items(num_tweets):\n",
    "    # Process a single status\n",
    "    print(\"Tweet ID:\", tweet.id)\n",
    "    print('Tweeted by ', tweet.user.screen_name)\n",
    "    print(\"Created at \",tweet.created_at)\n",
    "    print(\"Location: \",tweet.source)\n",
    "    print('Tweet Text: ', tweet.text)\n",
    "    print('-------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "We can view the available attributes to display by using Python `dir`\n",
    "method to perform introspection. In the following code cell we\n",
    "explicitly remove _class_ methods to minimize the display list and focus\n",
    "on the items of interest. After this, we display the Tweet in its raw\n",
    "JSON format by accessing the `_json` attribute.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ '_max_id', '_since_id', 'append', 'clear', 'completed_in', 'copy', 'count',\n",
      "  'extend', 'ids', 'index', 'insert', 'max_id', 'next_results', 'parse', 'pop',\n",
      "  'query', 'refresh_url', 'remove', 'reverse', 'since_id', 'sort']\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2, depth=2, width=80, compact=True)\n",
    "\n",
    "tweets = api.search(q='U2', rpp=1)\n",
    "\n",
    "pp.pprint([att for att in dir(tweets) if '__' not in att])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ '_api', '_json', 'author', 'contributors', 'coordinates', 'created_at',\n",
      "  'destroy', 'entities', 'favorite', 'favorite_count', 'favorited', 'geo', 'id',\n",
      "  'id_str', 'in_reply_to_screen_name', 'in_reply_to_status_id',\n",
      "  'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str',\n",
      "  'is_quote_status', 'lang', 'metadata', 'parse', 'parse_list', 'place',\n",
      "  'possibly_sensitive', 'quoted_status', 'quoted_status_id',\n",
      "  'quoted_status_id_str', 'retweet', 'retweet_count', 'retweeted', 'retweets',\n",
      "  'source', 'source_url', 'text', 'truncated', 'user']\n"
     ]
    }
   ],
   "source": [
    "# Pick a single tweet to analyze\n",
    "\n",
    "tweet = tweets[1]\n",
    "pp.pprint([att for att in dir(tweet) if '__' not in att])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'contributors': None,\n",
      "  'coordinates': None,\n",
      "  'created_at': 'Wed Mar 09 20:30:40 +0000 2016',\n",
      "  'entities': { 'hashtags': [],\n",
      "                'symbols': [],\n",
      "                'urls': [...],\n",
      "                'user_mentions': []},\n",
      "  'favorite_count': 0,\n",
      "  'favorited': False,\n",
      "  'geo': None,\n",
      "  'id': 707664923925594112,\n",
      "  'id_str': '707664923925594112',\n",
      "  'in_reply_to_screen_name': None,\n",
      "  'in_reply_to_status_id': None,\n",
      "  'in_reply_to_status_id_str': None,\n",
      "  'in_reply_to_user_id': None,\n",
      "  'in_reply_to_user_id_str': None,\n",
      "  'is_quote_status': True,\n",
      "  'lang': 'pl',\n",
      "  'metadata': {'iso_language_code': 'pl', 'result_type': 'recent'},\n",
      "  'place': None,\n",
      "  'possibly_sensitive': False,\n",
      "  'quoted_status': { 'contributors': None,\n",
      "                     'coordinates': None,\n",
      "                     'created_at': 'Wed Mar 09 20:25:32 +0000 2016',\n",
      "                     'entities': {...},\n",
      "                     'favorite_count': 9,\n",
      "                     'favorited': False,\n",
      "                     'geo': None,\n",
      "                     'id': 707663634470715392,\n",
      "                     'id_str': '707663634470715392',\n",
      "                     'in_reply_to_screen_name': None,\n",
      "                     'in_reply_to_status_id': None,\n",
      "                     'in_reply_to_status_id_str': None,\n",
      "                     'in_reply_to_user_id': None,\n",
      "                     'in_reply_to_user_id_str': None,\n",
      "                     'is_quote_status': False,\n",
      "                     'lang': 'pl',\n",
      "                     'metadata': {...},\n",
      "                     'place': None,\n",
      "                     'retweet_count': 1,\n",
      "                     'retweeted': False,\n",
      "                     'source': '<a href=\"http://twitter.com/download/iphone\" '\n",
      "                               'rel=\"nofollow\">Twitter for iPhone</a>',\n",
      "                     'text': 'W Tutce Kaczor Mniejszy olał sygnał PULL UP. '\n",
      "                             'Kaczor większy słyszy PULL UP dla PL, ale każe '\n",
      "                             'Błasikom przyspieszać. I gnają dalej. W ciemność',\n",
      "                     'truncated': False,\n",
      "                     'user': {...}},\n",
      "  'quoted_status_id': 707663634470715392,\n",
      "  'quoted_status_id_str': '707663634470715392',\n",
      "  'retweet_count': 0,\n",
      "  'retweeted': False,\n",
      "  'source': '<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web '\n",
      "            'Client</a>',\n",
      "  'text': 'Zważywszy,że pozostały Kaczor (większy), U2 odbiera: jako \"U-Dwa\" '\n",
      "          'nie możemy wiedzieć,jak odbiera PULL UP ;-) https://t.co/QTPxJmDeMv',\n",
      "  'truncated': False,\n",
      "  'user': { 'contributors_enabled': False,\n",
      "            'created_at': 'Mon Mar 31 21:48:56 +0000 2014',\n",
      "            'default_profile': False,\n",
      "            'default_profile_image': False,\n",
      "            'description': 'Dajmy PiSowi rządzić, a sam się wykończy. #KOD '\n",
      "                           'Europäer seit 30 Jahren.',\n",
      "            'entities': {...},\n",
      "            'favourites_count': 12330,\n",
      "            'follow_request_sent': False,\n",
      "            'followers_count': 805,\n",
      "            'following': False,\n",
      "            'friends_count': 745,\n",
      "            'geo_enabled': False,\n",
      "            'has_extended_profile': False,\n",
      "            'id': 2421102114,\n",
      "            'id_str': '2421102114',\n",
      "            'is_translation_enabled': False,\n",
      "            'is_translator': False,\n",
      "            'lang': 'de',\n",
      "            'listed_count': 10,\n",
      "            'location': 'Österreich',\n",
      "            'name': 'Peter Graviat',\n",
      "            'notifications': False,\n",
      "            'profile_background_color': 'C0DEED',\n",
      "            'profile_background_image_url': 'http://pbs.twimg.com/profile_background_images/644555749180485632/xV6-T4qm.png',\n",
      "            'profile_background_image_url_https': 'https://pbs.twimg.com/profile_background_images/644555749180485632/xV6-T4qm.png',\n",
      "            'profile_background_tile': False,\n",
      "            'profile_image_url': 'http://pbs.twimg.com/profile_images/677364965372731392/sSMvIzoV_normal.jpg',\n",
      "            'profile_image_url_https': 'https://pbs.twimg.com/profile_images/677364965372731392/sSMvIzoV_normal.jpg',\n",
      "            'profile_link_color': '0084B4',\n",
      "            'profile_sidebar_border_color': '000000',\n",
      "            'profile_sidebar_fill_color': '000000',\n",
      "            'profile_text_color': '000000',\n",
      "            'profile_use_background_image': True,\n",
      "            'protected': False,\n",
      "            'screen_name': 'PeterGravv',\n",
      "            'statuses_count': 11077,\n",
      "            'time_zone': 'Vienna',\n",
      "            'url': None,\n",
      "            'utc_offset': 3600,\n",
      "            'verified': False}}\n"
     ]
    }
   ],
   "source": [
    "# We can display the message data in JSON format\n",
    "\n",
    "pp.pprint(tweet._json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Trending\n",
    "\n",
    "Twitter tracks tweet data to identify topics or people that are being\n",
    "frequently mentioned, which is known as [_trending_][twtr]. The Twitter\n",
    "API enables an application to obtain a list of currently trending\n",
    "topics. These topics include metadata that can be used to learn more\n",
    "about trending topics. One component of the metadata is the physical\n",
    "location of the trending topic. This location is encoded as a\n",
    "[**WOEID**][woeid], which is a Yahoo developed standard that is short\n",
    "for _where on the earth ID_. In the first code cell below, we\n",
    "demonstrate obtaining the locations of currently trending topics before\n",
    "displaying these physical locations. In the second code cell, we display\n",
    "the complete metadata for one location, which can be used to obtain a\n",
    "list of trending topics for a particular location on Earth, via the\n",
    "WOEID. Note that since trending topics change, this Notebook will\n",
    "provide different results when run at different times.\n",
    "\n",
    "----\n",
    "[twtr]: https://dev.twitter.com/rest/reference/get/trends/available\n",
    "[woeid]: https://developer.yahoo.com/geo/geoplanet/guide/concepts.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WOEID Code (2972): Winnipeg, Canada\n",
      "WOEID Code (3369): Ottawa, Canada\n",
      "WOEID Code (3444): Quebec, Canada\n",
      "WOEID Code (3534): Montreal, Canada\n",
      "WOEID Code (4118): Toronto, Canada\n",
      "WOEID Code (8676): Edmonton, Canada\n",
      "WOEID Code (8775): Calgary, Canada\n",
      "WOEID Code (9807): Vancouver, Canada\n",
      "WOEID Code (12723): Birmingham, United Kingdom\n",
      "WOEID Code (12903): Blackpool, United Kingdom\n",
      "WOEID Code (13383): Bournemouth, United Kingdom\n",
      "WOEID Code (13911): Brighton, United Kingdom\n",
      "WOEID Code (13963): Bristol, United Kingdom\n",
      "WOEID Code (15127): Cardiff, United Kingdom\n",
      "WOEID Code (17044): Coventry, United Kingdom\n",
      "WOEID Code (18114): Derby, United Kingdom\n",
      "WOEID Code (19344): Edinburgh, United Kingdom\n",
      "WOEID Code (21125): Glasgow, United Kingdom\n",
      "WOEID Code (25211): Hull, United Kingdom\n"
     ]
    }
   ],
   "source": [
    "# Returns a JSON object that contains (a large number of) locations \n",
    "# that are currently trending.\n",
    "\n",
    "top_display = 20\n",
    "trending = api.trends_available()\n",
    "\n",
    "# We skip first value, which is entry for the World in JSON.\n",
    "for trend in trending[1:top_display]:\n",
    "    print('WOEID Code ({2:d}): {0}, {1}'.format(trend['name'], \\\n",
    "                                                trend['country'], trend['woeid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'country': 'United Kingdom',\n",
      "  'countryCode': 'GB',\n",
      "  'name': 'Blackpool',\n",
      "  'parentid': 23424975,\n",
      "  'placeType': {'code': 7, 'name': 'Town'},\n",
      "  'url': 'http://where.yahooapis.com/v1/place/12903',\n",
      "  'woeid': 12903}\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(trending[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UK Trends\n",
      "----------\n",
      "  #HeritageDiversity\n",
      "  #JuniorDoctorsStrike\n",
      "  #ffp16\n",
      "  #IWD2016\n",
      "  #InternationalWomensDay\n",
      "  Di Maria\n",
      "  Rabiot\n",
      "  Michael Owen\n",
      "  Kenedy\n",
      "  Ibra\n"
     ]
    }
   ],
   "source": [
    "# We can use a WOEID to find location specific trends.\n",
    "# Here we use the WOEID for the UK (from previous example)\n",
    "\n",
    "top_display = 10\n",
    "\n",
    "print(\"UK Trends\")\n",
    "print(10*'-')\n",
    "\n",
    "for trends in api.trends_place(id = 19344):\n",
    "    for trend in trends[\"trends\"][:top_display]:\n",
    "        print(\"  {0:s}\".format(trend[\"name\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### Student Activity\n",
    "\n",
    "In the preceding cells, we used the twitter API to obtain tweets and to\n",
    "identify trending topics. Now that you have run the Notebook, try making\n",
    "the following changes.\n",
    "\n",
    "1. Pick a particular twitter user and search their twitter stream.\n",
    "2. Pick a different location from the trending topics location list, and\n",
    "identify trending topics from a different WOEID.\n",
    "\n",
    "-----\n",
    "## Twitter text analysis\n",
    "\n",
    "We can now develop a text analysis project that uses twitter data. To\n",
    "simplify the application, we will use the NLTK twitter corpus.\n",
    "Otherwise, we would need a separate notebook to obtain the necessary\n",
    "tweets (because of the twitter rate limitation). The [NLTK twitter\n",
    "corpus][ntw] includes thirty thousand tweets retrieved from the twitter\n",
    "streaming API, the data have been cached on our course JupyterHub\n",
    "server. The tweets were explicitly selected from a recent election in\n",
    "the United Kingdom and one-third of them have been classified into\n",
    "positive or negative (with equal numbers of each). With these tweets, we\n",
    "can build a classification pipeline to perform sentiment analysis on\n",
    "twitter data.\n",
    "\n",
    "In the following code cells, we first obtain the tweets, build the numpy\n",
    "arrays for our classification pipeline, before constructing and testing\n",
    "this simple sentiment analysis text analysis application.\n",
    "\n",
    "-----\n",
    "[ntw]: http://www.nltk.org/howto/twitter.html#Using-a-Tweet-Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 Positive Tweets\n",
      "5000 Negative Tweets\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "tws = nltk.corpus.twitter_samples\n",
    "\n",
    "pos_tweets = np.array(tws.strings('positive_tweets.json'))\n",
    "neg_tweets = np.array(tws.strings('negative_tweets.json'))\n",
    "\n",
    "pos_labels = np.ones(pos_tweets.shape[0])\n",
    "neg_labels = np.zeros(neg_tweets.shape[0])\n",
    "\n",
    "targets = np.concatenate((pos_labels, neg_labels), axis=0)\n",
    "data = np.concatenate((pos_tweets, neg_tweets), axis = 0)\n",
    "\n",
    "print('{0} Positive Tweets'.format(pos_tweets.shape[0]))\n",
    "print('{0} Negative Tweets'.format(neg_tweets.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "We will employ 75% of the data for training, with 25% held out for\n",
    "validation. The classification pipeline will use a simply tokenizer to\n",
    "build a document-term matrix before applying a Naive Bayes classifier.\n",
    "The tokenizer will use _English_ stop words, will convert the text to\n",
    "all lowercase, and includes both unigrams and bigrams. Overall, this\n",
    "simple classification pipeline gives reasonable results.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    data, targets, test_size=0.25, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Positive       0.73      0.79      0.76      1240\n",
      "   Negative       0.78      0.71      0.74      1260\n",
      "\n",
      "avg / total       0.75      0.75      0.75      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "\n",
    "tools = [('cv', CountVectorizer()), ('nb', MultinomialNB())]\n",
    "pclf = Pipeline(tools)\n",
    "\n",
    "\n",
    "# Lowercase, English Stop Words, and unigrams and bigrams.\n",
    "pclf.set_params(cv__stop_words = 'english', \\\n",
    "                cv__ngram_range=(1,2), \\\n",
    "                cv__lowercase=True)\n",
    "\n",
    "pclf.fit(x_train, y_train)\n",
    "y_pred = pclf.predict(x_test)\n",
    "print(metrics.classification_report(y_test, y_pred, target_names = ['Positive', 'Negative']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### Blind Testing\n",
    "\n",
    "We can use the remaining twenty thousand tweets in the NLTK corpus for\n",
    "blind testing. We first obtain the tweets as a numpy array, before\n",
    "applying our sentiment analysis pipeline. Finally, we display the\n",
    "relative numbers of positive and negative classifications and we display\n",
    "examples of both positive and negative classified tweets.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unknown_tweets = np.array(tws.strings('tweets.20150430-223406.json'))\n",
    "unknown_pred = pclf.predict(unknown_tweets)\n",
    "\n",
    "unknown_pos = unknown_tweets[unknown_pred == 1]\n",
    "unknown_neg = unknown_tweets[unknown_pred == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 tweets to classify.\n",
      "8508 tweets classified as positive.\n",
      "11492 tweets classified as negative.\n",
      "---------------------------------------------------------------------------\n",
      "Sample Positve Tweet:\n",
      "---------------------------------------------------------------------------\n",
      "\"David Cameron: smooth, smiley but unconvincing\" #bbcqt http://t.co/mJ2ZkX1TjB\n",
      "---------------------------------------------------------------------------\n",
      "Sample Negatve Tweet:\n",
      "---------------------------------------------------------------------------\n",
      "RT @DouglasDaniel: Miliband's new line 'if you don't vote Labour in Scotland I will punish you by letting the Tories in'.\n"
     ]
    }
   ],
   "source": [
    "tweet_idx = 101\n",
    "\n",
    "print('{0} tweets to classify.'.format(unknown_tweets.shape[0]))\n",
    "print('{0} tweets classified as positive.'.format(unknown_pos.shape[0]))\n",
    "print('{0} tweets classified as negative.'.format(unknown_neg.shape[0]))\n",
    "\n",
    "print(75*'-')\n",
    "print('Sample Positve Tweet:')\n",
    "print(75*'-')\n",
    "print(unknown_pos[tweet_idx])\n",
    "\n",
    "print(75*'-')\n",
    "print('Sample Negatve Tweet:')\n",
    "print(75*'-')\n",
    "print(unknown_neg[tweet_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### Classifying new Tweets\n",
    "\n",
    "We can now combine everything covered in this notebook in order to apply\n",
    "our trained sentiment analysis pipeline on new twitter data. For this,\n",
    "we pick _random_ user, in this case CNN Political Twitter Feed (note\n",
    "this wasn't completely random. The training data was obtained from a\n",
    "similar feeds). We first obtain tweets from this user before creating\n",
    "the numpy arrays to use with our scikit learn classifier. Finally, we\n",
    "display the results of this sentiment analysis classifier. Note, since\n",
    "the tweets will change over time, the results presented in this Notebook\n",
    "will also change.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We obtained a sample of 65 tweets\n"
     ]
    }
   ],
   "source": [
    "newtweets = api.user_timeline(screen_name='@FoxNews', include_rts=False, count=100)\n",
    "                           \n",
    "print('We obtained a sample of {0} tweets'.format(len(newtweets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "for tweet in newtweets:\n",
    "    messages.append(tweet.text)\n",
    "    \n",
    "new_tweets = np.array(messages)\n",
    "new_pred = pclf.predict(new_tweets)\n",
    "\n",
    "new_pos = new_tweets[new_pred == 1]\n",
    "new_neg = new_tweets[new_pred == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 tweets to classify.\n",
      "38 tweets classified as positive.\n",
      "27 tweets classified as negative.\n",
      "---------------------------------------------------------------------------\n",
      "Sample Positve Tweet:\n",
      "---------------------------------------------------------------------------\n",
      "Do you agree with @Franklin_Graham? https://t.co/t1BrpkQVP4 https://t.co/oM3oGIRoTM\n",
      "---------------------------------------------------------------------------\n",
      "Sample Negatve Tweet:\n",
      "---------------------------------------------------------------------------\n",
      "BREAKING NEWS: Fox News projects @realDonaldTrump as the winner of the Hawaii Republican caucus.\n"
     ]
    }
   ],
   "source": [
    "tweet_idx = 13\n",
    "\n",
    "print('{0} tweets to classify.'.format(new_tweets.shape[0]))\n",
    "print('{0} tweets classified as positive.'.format(new_pos.shape[0]))\n",
    "print('{0} tweets classified as negative.'.format(new_neg.shape[0]))\n",
    "\n",
    "print(75*'-')\n",
    "print('Sample Positve Tweet:')\n",
    "print(75*'-')\n",
    "print(new_pos[tweet_idx])\n",
    "\n",
    "print(75*'-')\n",
    "print('Sample Negatve Tweet:')\n",
    "print(75*'-')\n",
    "print(new_neg[tweet_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### Student Activity\n",
    "\n",
    "In the preceding cells, we build a sentiment analysis classification\n",
    "pipeline by using the NLTK corpus before applying it to new tweets.Now\n",
    "that you have run the Notebook, try making the following changes.\n",
    "\n",
    "1. Modify the pipeline parameters, for example, apply stemming, change\n",
    "the `max_features`, or the number of n-grams. Can you improve the\n",
    "classification results on the validation data?\n",
    "\n",
    "2. Change the type of classification algorithm (e.g., random forest or\n",
    "SVC with regularization). Can you improve the classification results on\n",
    "the validation data?\n",
    "\n",
    "3. Using your new classification pipeline, examine the performance on\n",
    "the current twitter user. Look at other tweets, does the performance\n",
    "improve?\n",
    "\n",
    "4. Try classifying tweets from a different user, either an _election_\n",
    "type feed or a popular figure. By looking at select tweets and their\n",
    "classification, comment on how your classifier performs?\n",
    "\n",
    "Finally, why do you think the classification pipeline performs in the\n",
    "manner that is does (i.e., why are some tweets classified\n",
    "negative/positive)? Feel free to use the class forums.\n",
    "\n",
    "-----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
