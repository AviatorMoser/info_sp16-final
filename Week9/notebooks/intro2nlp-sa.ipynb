{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<DIV ALIGN=CENTER>\n",
    "\n",
    "# Introduction to NLP: Semantic Analysis\n",
    "## Professor Robert J. Brunner\n",
    "  \n",
    "</DIV>  \n",
    "-----\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Introduction\n",
    "\n",
    "Semantic Analysis\n",
    "Derive meaning from words, chunks, tokens.\n",
    "\n",
    "- wordnet\n",
    "- gensim\n",
    "- word2vec\n",
    "\n",
    "\n",
    "-----\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 total entries in synonym ring for drive. Only showing top 5 entries.\n",
      "----------------------------------------------------------------------\n",
      "drive (n): the act of applying force to propel something\n",
      "----------------------------------------------------------------------\n",
      "drive (n): a mechanism by which force or power is transmitted in a machine\n",
      "----------------------------------------------------------------------\n",
      "campaign (n): a series of actions advancing a principle or tending toward a particular end\n",
      "----------------------------------------------------------------------\n",
      "driveway (n): a road leading up to a private house\n",
      "----------------------------------------------------------------------\n",
      "drive (n): the trait of being highly motivated\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "max_entries = 5\n",
    "the_word = 'drive'\n",
    "the_synsets = wn.synsets(the_word)\n",
    "\n",
    "print('{0} total entries in synonym ring for {1}. '.format(len(the_synsets), the_word), end='')\n",
    "print('Only showing top {0} entries.'.format(max_entries))\n",
    "print(70*'-')\n",
    "\n",
    "for synset in the_synsets[:max_entries]:\n",
    "    vals = synset.name().split('.')\n",
    "    print('{0} ({1}): '.format(vals[0], vals[1]), end='')\n",
    "    print(synset.definition())\n",
    "    print(70*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive (n): Example: after reaching the desired velocity the drive is cut off\n",
      "    Lemma('drive.n.01.drive')\n",
      "    Lemma('drive.n.01.thrust')\n",
      "    Lemma('drive.n.01.driving_force')\n",
      "------------------------------------------------------------\n",
      "drive (n): Example: a variable speed drive permitted operation through a range of speeds\n",
      "    Lemma('drive.n.02.drive')\n",
      "------------------------------------------------------------\n",
      "campaign (n): Example: he supported populist campaigns\n",
      "    Lemma('campaign.n.02.campaign')\n",
      "    Lemma('campaign.n.02.cause')\n",
      "    Lemma('campaign.n.02.crusade')\n",
      "    Lemma('campaign.n.02.drive')\n",
      "    Lemma('campaign.n.02.movement')\n",
      "    Lemma('campaign.n.02.effort')\n",
      "------------------------------------------------------------\n",
      "driveway (n): Example: they parked in the driveway\n",
      "    Lemma('driveway.n.01.driveway')\n",
      "    Lemma('driveway.n.01.drive')\n",
      "    Lemma('driveway.n.01.private_road')\n",
      "------------------------------------------------------------\n",
      "drive (n): Example: his drive and energy exhausted his co-workers\n",
      "    Lemma('drive.n.05.drive')\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for synset in the_synsets[:max_entries]:\n",
    "    \n",
    "    vals = synset.name().split('.')\n",
    "    print('{0} ({1}): '.format(vals[0], vals[1]), end='')\n",
    "    if synset.examples():\n",
    "        print('Example: {0}'.format(synset.examples()[0]))\n",
    "        \n",
    "    for lma in synset.lemmas():\n",
    "        print('    {0}'.format(lma))\n",
    "\n",
    "    print(60*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define some words\n",
    "man = wn.synset('man.n.01')\n",
    "woman = wn.synset('woman.n.01')\n",
    "horse = wn.synset('horse.n.01')\n",
    "bird = wn.synset('bird.n.01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path Similarity:\n",
      "----------------------------------------\n",
      "man to woman: 0.333\n",
      "man to horse: 0.077\n",
      "man to bird: 0.125\n",
      "woman to woman: 1.000\n"
     ]
    }
   ],
   "source": [
    "fmt_str = '{1} to {2}: {0:4.3f}'\n",
    "\n",
    "print('Path Similarity:')\n",
    "print(40*'-')\n",
    "print(fmt_str.format(wn.path_similarity(man, woman), 'man', 'woman'))\n",
    "print(fmt_str.format(wn.path_similarity(man, horse), 'man', 'horse'))\n",
    "print(fmt_str.format(wn.path_similarity(man, bird), 'man', 'bird'))\n",
    "print(fmt_str.format(wn.path_similarity(woman, woman), 'woman', 'woman'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leacock-Chodorow Similarity:\n",
      "----------------------------------------\n",
      "man to woman: 2.539\n",
      "man to horse: 1.073\n",
      "man to bird: 1.558\n",
      "woman to woman: 3.638\n"
     ]
    }
   ],
   "source": [
    "print('Leacock-Chodorow Similarity:')\n",
    "print(40*'-')\n",
    "print(fmt_str.format(wn.lch_similarity(man, woman), 'man', 'woman'))\n",
    "print(fmt_str.format(wn.lch_similarity(man, horse), 'man', 'horse'))\n",
    "print(fmt_str.format(wn.lch_similarity(man, bird), 'man', 'bird'))\n",
    "print(fmt_str.format(wn.lch_similarity(woman, woman), 'woman', 'woman'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wu-Palmer Similarity:\n",
      "----------------------------------------\n",
      "man to woman: 0.667\n",
      "man to horse: 0.500\n",
      "man to bird: 0.632\n",
      "woman to woman: 0.667\n"
     ]
    }
   ],
   "source": [
    "print('Wu-Palmer Similarity:')\n",
    "print(40*'-')\n",
    "print(fmt_str.format(wn.wup_similarity(man, woman), 'man', 'woman'))\n",
    "print(fmt_str.format(wn.wup_similarity(man, horse), 'man', 'horse'))\n",
    "print(fmt_str.format(wn.wup_similarity(man, bird), 'man', 'bird'))\n",
    "print(fmt_str.format(wn.wup_similarity(woman, woman), 'woman', 'woman'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### Student Activity\n",
    "\n",
    "In the preceding cells, we . Now that you have run the Notebook,\n",
    "go back and make the following changes to see how the results change.\n",
    "\n",
    "1. Change \n",
    "2. Try \n",
    "3. Can \n",
    "\n",
    "----------\n",
    "\n",
    "## Gensim\n",
    "\n",
    "Now swich to gensim\n",
    "\n",
    "build topic models and use those for similarity\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# As a text example, we use the course description for INFO490  SP16.\n",
    "info_course = ['Advanced Data Science: This class is an asynchronous, online course.', \n",
    "               'This course will introduce advanced data science concepts by building on the foundational concepts presented in INFO 490: Foundations of Data Science.', \n",
    "               'Students will first learn how to perform more statistical data exploration and constructing and evaluating statistical models.', \n",
    "               'Next, students will learn machine learning techniques including supervised and unsupervised learning, dimensional reduction, and cluster finding.', \n",
    "               'An emphasis will be placed on the practical application of these techniques to high-dimensional numerical data, time series data, image data, and text data.', \n",
    "               'Finally, students will learn to use relational databases and cloud computing software components such as Hadoop, Spark, and NoSQL data stores.', \n",
    "               'Students must have access to a fairly modern computer, ideally that supports hardware virtualization, on which they can install software.', \n",
    "               'This class is open to sophomores, juniors, seniors and graduate students in any discipline who have either taken a previous INFO 490 data science course or have received instructor permission.']\n",
    "\n",
    "# Simple stop words\n",
    "stop_words = set('for a of the and to in on an'.split())\n",
    "\n",
    "# Parse text into words, make lowercase and remove stop words\n",
    "txts = [[word for word in sentance.lower().split() if word not in stop_words]\n",
    "        for sentance in info_course]\n",
    "\n",
    "# Keep only those words appearing more than once\n",
    "# Easy with a Counter, but need a flat list\n",
    "from collections import Counter\n",
    "frequency = Counter([word for txt in txts for word in txt])\n",
    "\n",
    "# Now grab tokens that appear more than once\n",
    "tokens = [[token for token in txt if frequency[token] > 1]\n",
    "          for txt in txts]\n",
    "\n",
    "from gensim import corpora\n",
    "dict_gensim = corpora.Dictionary(tokens)\n",
    "\n",
    "crps = [dict_gensim.doc2bow(txt) for txt in txts]\n",
    "\n",
    "from gensim import models\n",
    "\n",
    "tfidf = models.TfidfModel(crps)\n",
    "\n",
    "crps_tfidf = tfidf[crps]\n",
    "\n",
    "lda_gs = models.LdaModel(corpus=crps_tfidf, id2word=dict_gensim, num_topics=5, passes=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.066800291490970901), (1, 0.066799581386506865), (2, 0.068840948453476519), (3, 0.068986284952324783), (4, 0.72857289371672085)]\n"
     ]
    }
   ],
   "source": [
    "txt = 'Master Data Science'\n",
    "vec_bow = dict_gensim.doc2bow(txt.lower().split())\n",
    "vec_lda = lda_gs[vec_bow]\n",
    "print(vec_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.similarities.docsim:scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n"
     ]
    }
   ],
   "source": [
    "from gensim import similarities\n",
    "index = similarities.MatrixSimilarity(lda_gs[crps_tfidf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.9999097 ,  0.19364852,  0.28261018,  0.21369374,  0.25487536,\n",
       "        0.21060194,  0.25424922,  0.99906713], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index[vec_lda]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def find_similar_sentances(mdl, dct, sml_idx, txt, prct = 0.9):\n",
    "    vec_bow = dct.doc2bow(txt.lower().split())\n",
    "    vec_lda = mdl[vec_bow]\n",
    "    \n",
    "    sml = sorted(enumerate(sml_idx[vec_lda]), \\\n",
    "                 key=operator.itemgetter(1), reverse=True)\n",
    "    print('Score| Text')\n",
    "    print(4*'-', '|', 73*'-')\n",
    "    \n",
    "    for idx, val in sml:\n",
    "        if val > prct:\n",
    "            print('{0:4.3f}: {1}'.format(val, info_course[idx]))\n",
    "            print(4*'-', '|', 73*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score| Text\n",
      "---- | -------------------------------------------------------------------------\n",
      "1.000: Advanced Data Science: This class is an asynchronous, online course.\n",
      "---- | -------------------------------------------------------------------------\n",
      "0.999: This class is open to sophomores, juniors, seniors and graduate students in any discipline who have either taken a previous INFO 490 data science course or have received instructor permission.\n",
      "---- | -------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "find_similar_sentances(lda_gs, dict_gensim, index, txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score| Text\n",
      "---- | -------------------------------------------------------------------------\n",
      "0.987: This course will introduce advanced data science concepts by building on the foundational concepts presented in INFO 490: Foundations of Data Science.\n",
      "---- | -------------------------------------------------------------------------\n",
      "0.953: Students will first learn how to perform more statistical data exploration and constructing and evaluating statistical models.\n",
      "---- | -------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "txt = 'evaluate statistical plots'\n",
    "find_similar_sentances(lda_gs, dict_gensim, index, txt, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score| Text\n",
      "---- | -------------------------------------------------------------------------\n",
      "0.992: Next, students will learn machine learning techniques including supervised and unsupervised learning, dimensional reduction, and cluster finding.\n",
      "---- | -------------------------------------------------------------------------\n",
      "0.991: Finally, students will learn to use relational databases and cloud computing software components such as Hadoop, Spark, and NoSQL data stores.\n",
      "---- | -------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "txt = 'learn computing'\n",
    "find_similar_sentances(lda_gs, dict_gensim, index, txt, 0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### Student Activity\n",
    "\n",
    "In the preceding cells, we . Now that you have run the Notebook,\n",
    "go back and make the following changes to see how the results change.\n",
    "\n",
    "1. Change \n",
    "2. Try \n",
    "3. Can \n",
    "\n",
    "\n",
    "-----\n",
    "\n",
    "## Word2Vec\n",
    "\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "model = gensim.models.Word2Vec(txts, window=2, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.000: data to data\n",
      "-0.017: data to science\n",
      " 0.041: image to data\n",
      "-0.008: students to computing\n"
     ]
    }
   ],
   "source": [
    "# Compute cosine similarity between two words.\n",
    "\n",
    "def get_similarity(mdl, w1, w2):\n",
    "    sml = mdl.similarity(w1, w2)\n",
    "    print('{0:6.3f}: {1} to {2}'.format(sml, w1, w2))\n",
    "\n",
    "get_similarity(model, 'data', 'data')\n",
    "get_similarity(model, 'data', 'science')\n",
    "get_similarity(model, 'image', 'data')\n",
    "get_similarity(model, 'students', 'computing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "Larger corpus, use movie reviews\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "mvr = nltk.corpus.movie_reviews\n",
    "\n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "data_dir = '/home/data_scientist/data/nltk_data/corpora/movie_reviews'\n",
    "mvr = load_files(data_dir, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews in Corpus = 2000\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tokenizer = WordPunctTokenizer()\n",
    "\n",
    "new_mvr = []\n",
    "\n",
    "for mvr in mvr.data:\n",
    "    wtks = tokenizer.tokenize(mvr.decode('utf-8'))\n",
    "    new_mvr.append([wtk for wtk in wtks if wtk not in string.punctuation])\n",
    "\n",
    "print('Number of reviews in Corpus = {0}'.format(len(new_mvr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build word2vec model from movie reviews\n",
    "model = gensim.models.Word2Vec(new_mvr, window=5, min_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.000: girl to girl\n",
      " 0.771: boy to girl\n",
      " 0.829: woman to man\n",
      " 0.804: woman to girl\n"
     ]
    }
   ],
   "source": [
    "# Compute Cosine Similarities from Corpus\n",
    "get_similarity(model, 'girl', 'girl')\n",
    "get_similarity(model, 'boy', 'girl')\n",
    "get_similarity(model, 'woman', 'man')\n",
    "get_similarity(model, 'woman', 'girl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_words(vals, type='Cosine Similarity'):\n",
    "    print('{0:14s}: {1}'.format('Word', type))\n",
    "    print(40*'-')\n",
    "    for val in vals:\n",
    "        print('{0:14s}: {1:6.3f}'.format(val[0], val[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word          : Cosine Similarity\n",
      "----------------------------------------\n",
      "girl          :  0.771\n",
      "woman         :  0.735\n",
      "man           :  0.725\n",
      "immigrant     :  0.724\n",
      "hairdresser   :  0.697\n"
     ]
    }
   ],
   "source": [
    "#Compute cosine similarity between two words.\n",
    "\n",
    "vals = model.most_similar('boy', topn=5)\n",
    "show_words(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'boy'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify words that don't belong\n",
    "\n",
    "wrd_lst = ['boy', 'horse', 'cow', 'pig']\n",
    "\n",
    "model.doesnt_match(wrd_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity =  0.810\n"
     ]
    }
   ],
   "source": [
    "#Compute cosine similarity between two sets of words.\n",
    "\n",
    "val = model.n_similarity(['boy', 'girl'], ['man', 'woman'])\n",
    "\n",
    "print('Cosine Similarity = {0:6.3f}'.format(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word          : Cosine Similarity\n",
      "----------------------------------------\n",
      "fat           :  0.694\n",
      "drinks        :  0.664\n",
      "approaches    :  0.660\n",
      "prostitute    :  0.657\n",
      "benefactor    :  0.656\n"
     ]
    }
   ],
   "source": [
    "# Find similar words (Cosine Similarity)\n",
    "\n",
    "vals = model.most_similar(positive=['woman', 'girl'], negative=['man'], topn=5)\n",
    "show_words(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word          : CosMul Similarity\n",
      "----------------------------------------\n",
      "actress       :  0.825\n",
      "oscar         :  0.808\n",
      "nomination    :  0.798\n",
      "schwimmer     :  0.797\n",
      "performance   :  0.797\n"
     ]
    }
   ],
   "source": [
    "# Find similar words (Multiplicative Combination method)\n",
    "\n",
    "vals = model.most_similar_cosmul('actor', topn=5)\n",
    "show_words(vals, 'CosMul Similarity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Student Activity\n",
    "\n",
    "In the preceding cells, we . Now that you have run the Notebook,\n",
    "go back and make the following changes to see how the results change.\n",
    "\n",
    "1. Change \n",
    "2. Try \n",
    "3. Can \n",
    "\n",
    "-----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
